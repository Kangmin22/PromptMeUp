## ## 1. ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰`/api/run.js`

```jsx
// /api/run.js
import { kv } from '@vercel/kv';
import { handleAIGeneration, handleGeminiGeneration, handleLocalLlm } from '../lib/ai-handlers.js';

/**
 * í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì‚¬ìš©ì ì…ë ¥ì„ ì ìš©í•©ë‹ˆë‹¤.
 */
function applyTemplate(template, context) {
  return template.replace(/\{\{(.*?)\}\}/g, (match, key) => (context && context[key.trim()]) || '');
}

/**
 * @api {post} /api/run
 * @description íŠ¹ì • í”„ë¡¬í”„íŠ¸ë¥¼ ì¼íšŒì„±ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. (ëŒ€í™” ê¸°ë¡ ì—†ìŒ)
 * @param {string} promptId - ì‹¤í–‰í•  í”„ë¡¬í”„íŠ¸ì˜ ID
 * @param {string} versionTag - í”„ë¡¬í”„íŠ¸ì˜ ë²„ì „
 * @param {object} user_input - í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì£¼ì…í•  ê°’
 */
export default async function handler(req, res) {
  try {
    const { promptId, versionTag, user_input } = req.body;
    if (!promptId || !user_input || !versionTag) {
      return res.status(400).json({ error: "promptId, versionTag, user_inputì€ í•„ìˆ˜ì…ë‹ˆë‹¤." });
    }

    const promptData = await kv.get(`prompt:${promptId}:${versionTag}`);
    if (!promptData) {
      return res.status(404).json({ error: "í•´ë‹¹ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." });
    }
    
    const promptTemplate = Buffer.from(promptData.content, 'base64').toString('utf-8');
    const finalPrompt = applyTemplate(promptTemplate, user_input);
    const mode = promptData.metadata.execution_mode;

    let resultText;
    if (mode === 'ai_generation') {
      resultText = await handleAIGeneration(finalPrompt);
    } else if (mode === 'gemini_generation') {
      resultText = await handleGeminiGeneration(finalPrompt);
    } else if (mode === 'local_llm') {
      resultText = await handleLocalLlm(finalPrompt);
    } else {
      resultText = finalPrompt;
    }

    res.status(200).json({ result: resultText });
  } catch (e) {
    console.error('í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:', e);
    res.status(500).json({ error: e.message });
  }
};
```

---

## ## 2. AI í•¸ë“¤ëŸ¬ (`lib/ai-handlers.js`)

```jsx
// lib/ai-handlers.js
import OpenAI from 'openai';
import { GoogleGenerativeAI } from '@google/generative-ai';

/**
 * OpenAI API (gpt-3.5-turbo)ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. (ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì…ë ¥ìš©)
 * @param {string} prompt - AIì—ê²Œ ì „ë‹¬í•  ìµœì¢… í”„ë¡¬í”„íŠ¸
 * @returns {Promise<string>} AIê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸
 */
export async function handleAIGeneration(prompt) {
  // í•¨ìˆ˜ê°€ í˜¸ì¶œë  ë•Œë§Œ OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„± (Lazy Initialization)
  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
  const completion = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: prompt }],
  });
  return completion.choices[0].message.content;
}

/**
 * Google Gemini API (gemini-1.5-flash)ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. (ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì…ë ¥ìš©)
 * @param {string} prompt - AIì—ê²Œ ì „ë‹¬í•  ìµœì¢… í”„ë¡¬í”„íŠ¸
 * @returns {Promise<string>} AIê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸
 */
export async function handleGeminiGeneration(prompt) {
  // í•¨ìˆ˜ê°€ í˜¸ì¶œë  ë•Œë§Œ Gemini í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„± (Lazy Initialization)
  const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
  const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash"});
  const result = await model.generateContent(prompt);
  const response = await result.response;
  return response.text();
}

/**
 * ë¡œì»¬ Ollama ì„œë²„ì˜ /api/generate ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. (ë‹¨ìˆœ í…ìŠ¤íŠ¸ ìƒì„±ìš©)
 * @param {string} prompt - AIì—ê²Œ ì „ë‹¬í•  ìµœì¢… í”„ë¡¬í”„íŠ¸
 * @returns {Promise<string>} AIê°€ ìƒì„±í•œ í…ìŠ¤íŠ¸
 */
export async function handleLocalLlm(prompt) {
  const OLLAMA_API_URL = `http://${process.env.OLLAMA_HOST || '127.0.0.1'}:11434/api/generate`;
  const OLLAMA_DEFAULT_MODEL = 'gemma:2b-instruct-q4_0';
  
  try {
    const response = await fetch(OLLAMA_API_URL, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ model: OLLAMA_DEFAULT_MODEL, prompt: prompt, stream: false }),
    });
    if (!response.ok) {
      const errorBody = await response.text();
      throw new Error(`Ollama API ìš”ì²­ ì‹¤íŒ¨: ${response.status} ${errorBody}`);
    }
    const data = await response.json();
    return data.response;
  } catch (error) {
    console.error('Ollama í•¸ë“¤ëŸ¬ ì˜¤ë¥˜:', error);
    throw new Error('ë¡œì»¬ AI ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
  }
}

/**
 * Google Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ì±„íŒ…ìš©)
 * @param {Array<object>} messages - {role: '...', content: '...'} í˜•ì‹ì˜ ë©”ì‹œì§€ ë°°ì—´
 * @returns {Promise<string>} Geminiì˜ ì‘ë‹µ ë©”ì‹œì§€
 */
export async function handleGeminiChat(messages) {
  const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
  const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

  // Gemini APIëŠ” 'assistant' ì—­í• ì„ 'model'ë¡œ ì¸ì‹í•˜ë¯€ë¡œ ë³€í™˜í•´ì¤ë‹ˆë‹¤.
  const history = messages.slice(0, -1).map(msg => ({
    role: msg.role === 'assistant' ? 'model' : msg.role,
    parts: [{ text: msg.content }],
  }));

  const chat = model.startChat({ history: history });
  
  const lastMessage = messages[messages.length - 1];
  const result = await chat.sendMessage(lastMessage.content);
  const response = await result.response;
  return response.text();
}
```

---

## ## 3. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (`lib/orchestrator.js`)

```jsx
// lib/orchestrator.js
import { findModuleById } from './module-loader.js';
import { handleLocalLlm, handleGeminiGeneration } from './ai-handlers.js';
import { v4 as uuidv4 } from 'uuid';
import { generateEmbeddingForPrompt } from '../scripts/generate-embeddings.js';

/**
 * ì›Œí¬í”Œë¡œìš°ë¥¼ í†µí•´ ìƒì„±ëœ ìµœì¢… ê²°ê³¼ë¬¼ë“¤ì„ ì¡°í•©í•˜ì—¬,
 * ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‹œìŠ¤í…œì— ë“±ë¡í•˜ê³  ì„ë² ë”©ê¹Œì§€ ì™„ë£Œí•©ë‹ˆë‹¤.
 * @param {object} context - ëª¨ë“  ë‹¨ê³„ì˜ ê²°ê³¼ë¬¼ì´ ë‹´ê¸´ ì›Œí¬í”Œë¡œìš° ì»¨í…ìŠ¤íŠ¸ ê°ì²´
 * @returns {Promise<object>} /api/prompts APIì˜ ìµœì¢… ë“±ë¡ ê²°ê³¼ ê°ì²´
 */
async function assembleAndRegister(context) {
  // 1. ìµœì¢… í”„ë¡¬í”„íŠ¸ì˜ 'ë³¸ë¬¸'ì´ ë  ë‚´ìš©ì„ ì°¾ìŠµë‹ˆë‹¤. (YAML í¬ë§· ë‹¨ê³„ì˜ ê²°ê³¼ë¬¼)
  const finalPromptContent = context['export__final_prompt_yaml__v1'];
  if (!finalPromptContent) {
    throw new Error("ìµœì¢… í”„ë¡¬í”„íŠ¸ YAML(export__final_prompt_yaml__v1)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
  }

  // 2. í”„ë¡¬í”„íŠ¸ì˜ 'ë©”íƒ€ë°ì´í„°'ê°€ ë  ë‚´ìš©ì„ ì°¾ìŠµë‹ˆë‹¤. (ìë™ íƒœê¹… ë‹¨ê³„ì˜ ê²°ê³¼ë¬¼)
  let newMetadata = { generated_by: 'PromptMeUpBuilder' };
  const tagsOutput = context['meta__auto_tagger__v1'];
  if (tagsOutput) {
    try {
      const parsedTags = JSON.parse(tagsOutput.replace(/```json\n|```/g, ''));
      newMetadata = { ...newMetadata, ...parsedTags };
    } catch (e) {
      console.warn("íƒœê·¸ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨:", tagsOutput);
    }
  }

  // 3. ê³ ìœ  IDë¥¼ ê°€ì§„ ìƒˆ í”„ë¡¬í”„íŠ¸ë¥¼ ë“±ë¡í•©ë‹ˆë‹¤.
  const newPromptId = `generated-${uuidv4().slice(0, 8)}`;
  const versionTag = 'v1.0.0';
  const promptKey = `prompt:${newPromptId}:${versionTag}`;

  const registrationBody = {
    promptId: newPromptId,
    content: finalPromptContent,
    versionTag: versionTag,
    metadata: newMetadata,
  };
  
  console.log(`\nğŸ“¦ [${newPromptId}] ì´ë¦„ìœ¼ë¡œ ìƒˆ í”„ë¡¬í”„íŠ¸ë¥¼ ì‹œìŠ¤í…œì— ë“±ë¡í•©ë‹ˆë‹¤...`);
  console.log('ìµœì¢… ë©”íƒ€ë°ì´í„°:', registrationBody.metadata);

  const registrationUrl = process.env.VERCEL_URL
    ? `https://${process.env.VERCEL_URL}/api/prompts`
    : 'http://localhost:3000/api/prompts';

  const response = await fetch(registrationUrl, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(registrationBody)
  });

  if (!response.ok) {
    const errorBody = await response.text();
    throw new Error(`í”„ë¡¬í”„íŠ¸ ë“±ë¡ ì‹¤íŒ¨: ${errorBody}`);
  }

  const result = await response.json();
  console.log(`  âœ… ë“±ë¡ ì„±ê³µ!`);

  // 4. ë“±ë¡ ì„±ê³µ í›„, ì¦‰ì‹œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
  console.log(`\nğŸ“Š ì´ì–´ì„œ [${newPromptId}] í”„ë¡¬í”„íŠ¸ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤...`);
  await generateEmbeddingForPrompt(promptKey);

  return result;
}

/**
 * ì •ì˜ëœ ì›Œí¬í”Œë¡œìš°ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ê³ , ì§€ì •ëœ ìµœì¢… ì¶œë ¥ ëª¨ë“ˆì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
 * @param {string[]} workflow - ì‹¤í–‰í•  ëª¨ë“ˆ IDì˜ ë°°ì—´
 * @param {string} initialInput - ìµœì´ˆ ì‚¬ìš©ì ì…ë ¥
 * @param {string} finalOutputModuleId - ìµœì¢…ì ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•  ëª¨ë“ˆì˜ ID. 'register_and_embed'ë¥¼ ì „ë‹¬í•˜ë©´ ìµœì¢… ë“±ë¡ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
 * @returns {Promise<any>} ì§€ì •ëœ ìµœì¢… ëª¨ë“ˆì˜ ê²°ê³¼ë¬¼ ë˜ëŠ” ë“±ë¡ ê²°ê³¼ ê°ì²´
 */
export async function runWorkflow(workflow, initialInput, finalOutputModuleId) {
  console.log(`ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹œì‘: ${workflow.length}ê°œì˜ ë‹¨ê³„`);
  
  const workflowContext = { initialInput: initialInput };
  let currentInput = initialInput;

  for (const moduleId of workflow) {
    console.log(`\nâ–¶ï¸ [${moduleId}] ëª¨ë“ˆ ì‹¤í–‰ ì¤‘...`);
    const module = findModuleById(moduleId);

    if (!module) { throw new Error(`ì˜¤ë¥˜: ëª¨ë“ˆ ID [${moduleId}]ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`); }
    if (!module.prompt_template) { throw new Error(`ì˜¤ë¥˜: ëª¨ë“ˆ [${moduleId}]ì— prompt_templateì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`); }
    
    // íŠ¹ì • ëª¨ë“ˆë“¤ì€ ì´ì „ ë‹¨ê³„ ê²°ê³¼ê°€ ì•„ë‹Œ, ì „ì²´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤.
    const inputForThisStep = moduleId.startsWith('validation__') || moduleId.startsWith('export__') || moduleId.startsWith('meta__')
      ? JSON.stringify(workflowContext, null, 2)
      : currentInput;

    const finalPrompt = module.prompt_template.replace('{{input}}', inputForThisStep);

    let output;
    // ë³µì¡í•˜ê±°ë‚˜ ì°½ì˜ì ì¸ ì‘ì—…ì€ Gemini, ê·¸ ì™¸ëŠ” ë¡œì»¬ AIë¥¼ ì‚¬ìš©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ
    if (moduleId.startsWith('example_generator__') || moduleId.startsWith('validation__') || moduleId.startsWith('meta__auto_tagger')) {
      console.log(`  ğŸ”¥ Creative/Complex Task! Gemini AIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...`);
      output = await handleGeminiGeneration(finalPrompt);
    } else {
      console.log('  âš¡ï¸ Structural Task! Local AIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...`);
      output = await handleLocalLlm(finalPrompt);
    }
    
    console.log(`  âœ… ì™„ë£Œ: ${module.name}`);
    workflowContext[moduleId] = output;
    currentInput = output;
  }

  console.log('\nâœ¨ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì™„ë£Œ!');
  
  // ìµœì¢… ëª©í‘œê°€ 'ë“±ë¡'ì¼ ê²½ìš°, ì¡°ë¦½ ë° ë“±ë¡ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
  if (finalOutputModuleId === 'register_and_embed') {
    return await assembleAndRegister(workflowContext);
  }

  // ê·¸ ì™¸ì˜ ê²½ìš°, ì§€ì •ëœ ëª¨ë“ˆì˜ ê²°ê³¼ë¬¼ì„ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.
  return workflowContext[finalOutputModuleId];
}
```

---

## ## 4. ì±„íŒ… API (`/api/chat.js`)

```jsx
// /api/chat.js
import { kv } from '@vercel/kv';
import { handleGeminiChat } from '../lib/ai-handlers.js';

/**
 * ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ YAML ë¬¸ìì—´ì—ì„œ ì‹¤ì œ AIê°€ ë”°ë¼ì•¼ í•  ì§€ì‹œì‚¬í•­ ë¶€ë¶„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
 * @param {string} rawPrompt - Base64ë¡œ ë””ì½”ë”©ëœ í”„ë¡¬í”„íŠ¸ YAML ì›ë³¸ ë¬¸ìì—´
 * @returns {string} ì •ì œëœ ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­
 */
function refineSystemPrompt(rawPrompt) {
  // "**Instructions**" ì„¹ì…˜ë¶€í„° "**Context**" ë˜ëŠ” "**Examples**" ì„¹ì…˜ ì „ê¹Œì§€ì˜ ë‚´ìš©ì„ ì¶”ì¶œ
  const instructionMatch = rawPrompt.match(/\*\*Instructions\*\*\s*([\s\S]*?)\s*(?=\*\*Context\*\*|\*\*Examples\*\*|$)/);
  if (instructionMatch && instructionMatch[1]) {
    return instructionMatch[1].trim();
  }
  // ë§Œì•½ Instructions ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•˜ë©´, ì›ë³¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì•ˆì „ì¥ì¹˜)
  return rawPrompt;
}

/**
 * @api {post} /api/chat
 * @description agentIdë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§€ì†ì ì¸ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 * @param {string} agentId - ëŒ€í™” ì„¸ì…˜ì„ ì‹ë³„í•˜ëŠ” ê³ ìœ  ID
 * @param {string} userInput - í˜„ì¬ ì‚¬ìš©ìì˜ ì…ë ¥ ë©”ì‹œì§€
 */
export default async function handler(req, res) {
  try {
    const { agentId, userInput } = req.body;
    if (!agentId || !userInput) {
      return res.status(400).json({ error: "agentIdì™€ userInputì€ í•„ìˆ˜ì…ë‹ˆë‹¤." });
    }

    // 1. ì—ì´ì „íŠ¸ì˜ ê¸°ë³¸ ì—­í• ì„ ì •ì˜í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    // (í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ íŠ¹ì • IDë¥¼ í•˜ë“œì½”ë”©. ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” agentIdë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°íšŒí•´ì•¼ í•¨)
    const basePromptKey = 'prompt:generated-f4b8bd61:v1.0.0';
    const promptData = await kv.get(basePromptKey);
    if (!promptData) {
      return res.status(404).json({ error: "ì—ì´ì „íŠ¸ì˜ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." });
    }
    const rawPromptContent = Buffer.from(promptData.content, 'base64').toString('utf-8');

    // 2. í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ AIê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í•µì‹¬ ì§€ì‹œì‚¬í•­ìœ¼ë¡œ ì •ì œí•©ë‹ˆë‹¤.
    const systemInstruction = refineSystemPrompt(rawPromptContent);
    
    // 3. ì´ ì—ì´ì „íŠ¸ì˜ ì´ì „ ëŒ€í™” ê¸°ë¡(ë©”ëª¨ë¦¬)ì„ KV ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    const memoryKey = `agent:${agentId}:memory`;
    const conversationHistory = await kv.get(memoryKey) || [];

    // 4. AIì—ê²Œ ì „ë‹¬í•  êµ¬ì¡°í™”ëœ ë©”ì‹œì§€ ë°°ì—´ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
    const messages = [];
    
    // ëŒ€í™”ì˜ ì²« í„´ì¼ ê²½ìš°ì—ë§Œ ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­ì„ ì£¼ì…í•©ë‹ˆë‹¤.
    if (conversationHistory.length === 0) {
      const firstUserInput = `
ë„ˆëŠ” ì§€ê¸ˆë¶€í„° ì•„ë˜ì˜ ì§€ì‹œì‚¬í•­ì„ ë”°ë¼ì•¼ í•˜ëŠ” AI ì—ì´ì „íŠ¸ë‹¤.
---
${systemInstruction}
---

ì´ì œ ì²« ë²ˆì§¸ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•´ë¼.
ì‚¬ìš©ì: ${userInput}
`;
      messages.push({ role: 'user', content: firstUserInput });
    } else {
      // ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë©”ì‹œì§€ ë°°ì—´ì— ì¶”ê°€
      conversationHistory.forEach(turn => {
        messages.push({ role: 'user', content: turn.userInput });
        messages.push({ role: 'assistant', content: turn.assistantResponse });
      });
      // í˜„ì¬ ì‚¬ìš©ì ì…ë ¥ì„ ë§ˆì§€ë§‰ì— ì¶”ê°€
      messages.push({ role: 'user', content: userInput });
    }

    // 5. ëŒ€í™”ì— ìµœì í™”ëœ Gemini í•¸ë“¤ëŸ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    const assistantResponse = await handleGeminiChat(messages);

    // 6. ìƒˆë¡œìš´ ëŒ€í™” ë‚´ìš©ì„ ê¸°ë¡ì— ì¶”ê°€í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    const newHistory = [...conversationHistory, { userInput: userInput, assistantResponse }];
    await kv.set(memoryKey, newHistory);

    res.status(200).json({ response: assistantResponse });

  } catch (e) {
    console.error('ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:', e);
    res.status(500).json({ error: e.message });
  }
};
```

---

## ## 5. í”„ë¡¬í”„íŠ¸ ë“±ë¡ `/api/prompts.js`

```jsx
// /api/prompts.js
import { kv } from '@vercel/kv';

/**
 * @api {post} /api/prompts
 * @description ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¥¼ ì‹œìŠ¤í…œì— ë“±ë¡í•©ë‹ˆë‹¤.
 * @param {string} promptId - ìƒˆ í”„ë¡¬í”„íŠ¸ì˜ ê³ ìœ  ID
 * @param {string} content - í”„ë¡¬í”„íŠ¸ì˜ ë‚´ìš© (ì¼ë°˜ í…ìŠ¤íŠ¸)
 * @param {string} versionTag - í”„ë¡¬í”„íŠ¸ì˜ ë²„ì „
 * @param {object} metadata - ì‹¤í–‰ ëª¨ë“œ, ì¹´í…Œê³ ë¦¬ ë“± ì¶”ê°€ ì •ë³´
 */
export default async function handler(req, res) {
  try {
    const { promptId, content, versionTag, metadata } = req.body;

    if (!promptId || !content) {
      return res.status(400).json({ error: "promptId, contentëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤." });
    }
    
    // ì„œë²„ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ Base64 ì¸ì½”ë”©ì„ ìˆ˜í–‰
    const encodedContent = Buffer.from(content, 'utf-8').toString('base64');
    
    await kv.set(`prompt:${promptId}:${versionTag}`, { content: encodedContent, metadata });

    res.status(201).json({ 
      message: "í”„ë¡¬í”„íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", 
      promptId, 
      versionTag,
    });

  } catch (e) {
    console.error('í”„ë¡¬í”„íŠ¸ ë“±ë¡ ì¤‘ ì˜¤ë¥˜:', e);
    res.status(500).json({ error: e.message });
  }
};
```

---

## ## 6. ë°°ì¹˜ ì‹¤í–‰ `/api/batch-run.js`

```jsx
// /api/batch-run.js
import { kv } from '@vercel/kv';
import { handleAIGeneration, handleGeminiGeneration, handleLocalLlm } from '../lib/ai-handlers.js';

/**
 * ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜
 */
async function processSinglePrompt(request) {
  const { promptId, versionTag, user_input } = request;

  if (!promptId || !user_input || !versionTag) {
    return { error: "promptId, versionTag, user_inputì€ í•„ìˆ˜ì…ë‹ˆë‹¤.", request };
  }

  const promptData = await kv.get(`prompt:${promptId}:${versionTag}`);
  if (!promptData) {
    return { error: "í•´ë‹¹ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", request };
  }

  const promptTemplate = Buffer.from(promptData.content, 'base64').toString('utf-8');
  const finalPrompt = promptTemplate.replace(/\{\{(.*?)\}\}/g, (match, key) => (user_input && user_input[key.trim()]) || '');
  const mode = promptData.metadata.execution_mode;

  let resultText;
  if (mode === 'ai_generation') {
    resultText = await handleAIGeneration(finalPrompt);
  } else if (mode === 'gemini_generation') {
    resultText = await handleGeminiGeneration(finalPrompt);
  } else if (mode === 'local_llm') {
    resultText = await handleLocalLlm(finalPrompt);
  } else {
    resultText = finalPrompt;
  }
  
  return { result: resultText, request };
}

/**
 * @api {post} /api/batch-run
 * @description ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ìš”ì²­ì„ ë°°ì—´ë¡œ ë°›ì•„ ë™ì‹œì— ì²˜ë¦¬í•©ë‹ˆë‹¤.
 * @param {Array<object>} - ê° ìš”ì†ŒëŠ” /api/runì˜ bodyì™€ ë™ì¼í•œ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
 */
export default async function handler(req, res) {
  try {
    if (!Array.isArray(req.body)) {
      return res.status(400).json({ error: "ìš”ì²­ì€ ë°˜ë“œì‹œ ë°°ì—´ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤." });
    }

    const requests = req.body;
    
    // Promise.allì„ ì‚¬ìš©í•´ì„œ ëª¨ë“  ìš”ì²­ì„ ë³‘ë ¬ë¡œ ë™ì‹œì— ì²˜ë¦¬
    const promises = requests.map(request => processSinglePrompt(request));
    const results = await Promise.all(promises);

    res.status(200).json(results);
  } catch (e) {
    console.error('ë°°ì¹˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:', e);
    res.status(500).json({ error: 'ë°°ì¹˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
};
```

---

## ## 7. ìœ ì‚¬ë„ ê²€ìƒ‰ `/api/find-similar.js`

```jsx
// /api/find-similar.js
import { kv } from '@vercel/kv';
import { cosineSimilarity } from '../lib/utils.js';

/**
 * @api {get} /api/find-similar
 * @description íŠ¹ì • í”„ë¡¬í”„íŠ¸ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
 * @param {string} promptId - ê¸°ì¤€ì´ ë  í”„ë¡¬í”„íŠ¸ì˜ ID
 * @param {string} versionTag - í”„ë¡¬í”„íŠ¸ì˜ ë²„ì „
 */
export default async function handler(req, res) {
  try {
    const { promptId, versionTag } = req.query;
    if (!promptId || !versionTag) {
      return res.status(400).json({ error: "promptIdì™€ versionTagëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤." });
    }

    const targetKey = `embedding:${promptId}:${versionTag}`;
    const targetVector = await kv.get(targetKey);
    if (!targetVector) {
      return res.status(404).json({ error: "ê¸°ì¤€ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤." });
    }

    const allEmbeddingKeys = [];
    for await (const key of kv.scanIterator({ match: 'embedding:*' })) {
      allEmbeddingKeys.push(key);
    }
    
    const allVectors = await kv.mget(...allEmbeddingKeys);
    const similarities = [];

    for (let i = 0; i < allEmbeddingKeys.length; i++) {
      const currentKey = allEmbeddingKeys[i];
      if (currentKey === targetKey) continue;

      const currentVector = allVectors[i];
      if (currentVector) {
        const similarity = cosineSimilarity(targetVector, currentVector);
        similarities.push({
          key: currentKey.replace('embedding:', 'prompt:'),
          similarity: similarity,
        });
      }
    }

    similarities.sort((a, b) => b.similarity - a.similarity);
    res.status(200).json(similarities);
  } catch (error) {
    console.error('ìœ ì‚¬ í”„ë¡¬í”„íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜:', error);
    res.status(500).json({ error: 'ìœ ì‚¬ í”„ë¡¬í”„íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' });
  }
};
```

---

## ## 8. ë¹Œë” ì—”ì§„ í…ŒìŠ¤íŠ¸ìš© `/scripts/test-orchestrator.js`

```jsx
// scripts/test-orchestrator.js
import dotenv from 'dotenv';
dotenv.config({ path: '.env.development.local' });

import { runWorkflow } from '../lib/orchestrator.js';

/**
 * @fileoverview PromptMeUp ë¹Œë” ì—”ì§„ì˜ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.
 * ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥ë°›ì•„ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±, ê²€ì¦, íŒ¨í‚¤ì§• í›„ ìµœì¢…ì ìœ¼ë¡œ ì‹œìŠ¤í…œì— ë“±ë¡í•˜ê³  ì„ë² ë”©ê¹Œì§€ ì™„ë£Œí•©ë‹ˆë‹¤.
 */

// í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì˜ˆì‹œ ì‚¬ìš©ì ì•„ì´ë””ì–´
const userInput = "ìš°ë¦¬ ë™ë„¤ ë§›ì§‘ì„ ì¶”ì²œí•´ì£¼ëŠ” ì±—ë´‡ì„ ë§Œë“¤ì–´ì¤˜. ìœ„ì¹˜ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí•˜ê³ , ë¦¬ë·°ë„ ìš”ì•½í•´ì¤¬ìœ¼ë©´ ì¢‹ê² ì–´.";

// ì‹¤í–‰í•  ì „ì²´ ëª¨ë“ˆ íŒŒì´í”„ë¼ì¸
const workflow = [
  'input__core_extract__v1',
  'logic__directive_translate__v1',
  'structure__separate_instruction_context__v1',
  'logic__optimize_expression__v1',
  'example_generator__positive_negative__v1',
  'validation__conflict_detector__v1',
  'export__final_prompt_yaml__v1',
  'meta__auto_tagger__v1'
];

async function main() {
  console.log('--- ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ë“±ë¡ ì›Œí¬í”Œë¡œìš° ---');
  console.log('ì‚¬ìš©ì ì…ë ¥:', userInput);
  try {
    // ìµœì¢… ëª©í‘œëŠ” 'ë“±ë¡ ë° ì„ë² ë”©'ì´ë¼ê³  ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    const finalResult = await runWorkflow(workflow, userInput, 'register_and_embed');
    console.log('\n--- ğŸš€ ìµœì¢… ë“±ë¡ëœ í”„ë¡¬í”„íŠ¸ ì •ë³´ ---');
    console.dir(finalResult, { depth: null });
  } catch (error) {
    console.error('\n--- ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ---');
    console.error(error.message);
  }
}

main();
```

## ## 9. í”„ë¡¬í”„íŠ¸ ì¬ì‹¤í–‰ìš© `/scripts/replay.js`

```jsx
// scripts/replay.js
import dotenv from 'dotenv';
dotenv.config({ path: '.env.development.local' });
import fs from 'fs/promises';

/**
 * @fileoverview íŠ¹ì • IDì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì¬ì‹¤í–‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ í„°ë¯¸ë„ê³¼ ë¡œê·¸ íŒŒì¼ì— ì¶œë ¥í•©ë‹ˆë‹¤.
 * @usage npm run replay [promptId]
 */

async function replayPrompt() {
  // node, replay.js, [promptId] ìˆœì„œì´ë¯€ë¡œ 3ë²ˆì§¸ ì¸ìë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
  const promptId = process.argv[2]; 
  
  if (!promptId) {
    console.error('âŒ ì˜¤ë¥˜: promptIdê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜ˆ: npm run replay local-hello');
    return;
  }

  console.log(`â–¶ï¸ í”„ë¡¬í”„íŠ¸ [${promptId}]ë¥¼ ì¬ì‹¤í–‰í•©ë‹ˆë‹¤...`);

  try {
    const response = await fetch('http://localhost:3000/api/run', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        promptId: promptId,
        versionTag: 'v1.0.0', // ì§€ê¸ˆì€ v1.0.0ìœ¼ë¡œ ê³ ì •
        user_input: {} // ì¬ì‹¤í–‰ ì‹œì—ëŠ” ë¹ˆ ê°’ìœ¼ë¡œ ì‹œì‘
      }),
    });

    const result = await response.json();

    if (!response.ok) {
      throw new Error(result.error || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    }

    console.log('âœ… ì‹¤í–‰ ì„±ê³µ!');
    console.log('\n--- AI ì‘ë‹µ ê²°ê³¼ ---');
    console.log(result.result);

    // ì‘ë‹µ ê²°ê³¼ë¥¼ ë¡œê·¸ íŒŒì¼ë¡œ ì €ì¥
    const logFileName = `logs/replay-${promptId}-${new Date().getTime()}.json`;
    await fs.mkdir('logs', { recursive: true });
    await fs.writeFile(logFileName, JSON.stringify(result, null, 2));
    console.log(`\nğŸ“„ ë¡œê·¸ê°€ ${logFileName} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.`);

  } catch (error) {
    console.error(`\nâŒ í”„ë¡¬í”„íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:`, error.message);
  }
}

replayPrompt();
```

---
## ## 10. ìœ ì‚¬ë„ ê²€ìƒ‰ìš© `/scripts/search.js`

```jsx
// scripts/search.js
import dotenv from 'dotenv';
dotenv.config({ path: '.env.development.local' });

import { kv } from '@vercel/kv';
import EmbeddingPipelineSingleton from './embedding-pipeline.js';
import { cosineSimilarity } from '../lib/utils.js';

/**
 * @fileoverview ìì—°ì–´ ê²€ìƒ‰ì–´ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
 * @usage npm run search "[search query]"
 */
async function searchSimilarPrompts() {
  const query = process.argv[2];
  if (!query) {
    console.error('âŒ ì˜¤ë¥˜: ê²€ìƒ‰ì–´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì˜ˆ: npm run search "ê°•ë‚¨ ë§›ì§‘ ì±—ë´‡"');
    return;
  }

  console.log(`ğŸ” ê²€ìƒ‰ì–´ "${query}"ì™€(ê³¼) ìœ ì‚¬í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤...`);

  try {
    // 1. ì‚¬ìš©ì ê²€ìƒ‰ì–´ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    const extractor = await EmbeddingPipelineSingleton.getInstance();
    const queryEmbedding = await extractor(query, { pooling: 'mean', normalize: true });
    const queryVector = Array.from(queryEmbedding.data);

    // 2. ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  ì„ë² ë”©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    const allEmbeddingKeys = [];
    for await (const key of kv.scanIterator({ match: 'embedding:*' })) {
      allEmbeddingKeys.push(key);
    }
    const allVectors = await kv.mget(...allEmbeddingKeys);

    // 3. ëª¨ë“  í”„ë¡¬í”„íŠ¸ ë²¡í„°ì™€ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    const similarities = [];
    for (let i = 0; i < allEmbeddingKeys.length; i++) {
      const currentKey = allEmbeddingKeys[i];
      const currentVector = allVectors[i];
      if (currentVector) {
        const similarity = cosineSimilarity(queryVector, currentVector);
        similarities.push({
          key: currentKey.replace('embedding:', 'prompt:'),
          similarity: similarity,
        });
      }
    }

    // 4. ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 5ê°œë¥¼ í…Œì´ë¸”ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
    similarities.sort((a, b) => b.similarity - a.similarity);
    const top5 = similarities.slice(0, 5);

    console.log('\n--- ğŸš€ ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼ (Top 5) ---');
    console.table(top5);

  } catch (error) {
    console.error('\nâŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', error.message);
  }
}

searchSimilarPrompts();
```
